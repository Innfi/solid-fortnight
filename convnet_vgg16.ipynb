{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb79883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532a4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!mv kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition\n",
    "!unzip -qq dogs-vs-cats-redux-kernels-edition.zip\n",
    "!unzip -qq train.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c961e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib\n",
    "\n",
    "original_dir = pathlib.Path(\"train\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n",
    "\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "  for category in (\"cat\", \"dog\"):\n",
    "    dir = new_base_dir / subset_name / category\n",
    "    os.makedirs(dir)\n",
    "    fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "    for fname in fnames:\n",
    "      shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
    "\n",
    "make_subset(\"train\", start_index=0, end_index=1000)\n",
    "make_subset(\"validation\", start_index=1000, end_index=1500)\n",
    "make_subset(\"test\", start_index=1500, end_index=2500)\n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "  new_base_dir / \"train\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32)\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "  new_base_dir / \"validation\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32)\n",
    "test_dataset = image_dataset_from_directory(\n",
    "  new_base_dir / \"test\",\n",
    "  image_size=(180, 180),\n",
    "  batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda9cd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(180, 180, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a309252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_features_and_labels(dataset):\n",
    "  all_features = []\n",
    "  all_labels = []\n",
    "  for images, labels in dataset:\n",
    "    preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n",
    "    features = conv_base.predict(preprocessed_images)\n",
    "    all_features.append(features)\n",
    "    all_labels.append(labels)\n",
    "  return np.concatenate(all_features), np.concatenate(all_labels)\n",
    "\n",
    "train_features, train_labels = get_features_and_labels(train_dataset)\n",
    "validation_features, validation_labels = get_features_and_labels(validation_dataset)\n",
    "test_features, test_labels = get_features_and_labels(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded6655",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(5, 5, 512))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.Dropout(0.0)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"feature_extraction.keras\",\n",
    "        save_best_only=True,\n",
    "        monitor=\"val_loss\")\n",
    "]\n",
    "\n",
    "fit_result = model.fit(train_features, \n",
    "                       train_labels, \n",
    "                       epochs=20,\n",
    "                       validation_data=(validation_features, validation_labels),\n",
    "                       callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207546e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accuracy = fit_result.history[\"accuracy\"]\n",
    "val_accuracy = fit_result.history[\"val_accuracy\"]\n",
    "loss = fit_result.history[\"loss\"]\n",
    "val_loss = fit_result.history[\"val_loss\"]\n",
    "epochs = range(1, len(accuracy)+1)\n",
    "\n",
    "plt.plot(epochs, accuracy, \"bo\", label=\"training accuracy\")\n",
    "plt.plot(epochs, val_accuracy, \"b\", label=\"validation accuracy\")\n",
    "plt.title(\"training and validation accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, \"bo\", label=\"training loss\")\n",
    "plt.plot(epochs, val_loss, \"b\", label=\"validation loss\")\n",
    "plt.title(\"training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
